{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ02k7oJAcEU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iUF4FcBv0nW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce07c2b5-8be7-4e79-b125-439f54358b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/drive/MyDrive/skin disease'\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "data_dir"
      ],
      "metadata": {
        "id": "nux2ocUH0pX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefcc780-9c4b-4cf3-fae5-d179a0bcfc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/skin disease')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Acne= list(data_dir.glob('Acne/*'))\n",
        "Eczema= list(data_dir.glob('Eczema/*'))\n",
        "Psoriasis= list(data_dir.glob('Psoriasis_and_LP/*'))\n",
        "Ringworm= list(data_dir.glob('Ringworm/*'))"
      ],
      "metadata": {
        "id": "KB2UcfYW02Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contains the images path\n",
        "df_images = {\n",
        "'Acne':Acne,\n",
        "'Eczema':Eczema,\n",
        "'Psoriasis':Psoriasis,\n",
        "'Ringworm':Ringworm,\n",
        "}\n",
        "\n",
        "# Contains numerical labels for the categories\n",
        "df_labels = {\n",
        "'Acne':0,\n",
        "'Eczema':1,\n",
        "'Psoriasis':2,\n",
        "'Ringworm':3,\n",
        "}"
      ],
      "metadata": {
        "id": "7otG772Q07vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "X=[]\n",
        "y=[]\n",
        "for label, images in df_images.items():\n",
        "    for image in images:\n",
        "        img=cv.imread(str(image))\n",
        "        img=cv.resize(img,(224,224))\n",
        "        img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
        "        X.append(img)\n",
        "        y.append(df_labels[label])"
      ],
      "metadata": {
        "id": "P8PlKs7W098o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fl1UcW5cXJ3V",
        "outputId": "0f25e224-1921-4d9f-886c-6f50037879bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "32AIw1FLllXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)"
      ],
      "metadata": {
        "id": "aSUp5S0Llvxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdtAJ6NLlzH4",
        "outputId": "20eaf727-b273-4d44-cf57-b3dd495f6451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5222,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_RW6HR-l1_I",
        "outputId": "eb053f45-47fc-45b0-eb74-733ca45022ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5222, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,random_state=42)"
      ],
      "metadata": {
        "id": "0TZT03v04yG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6xc27Y7jbE2",
        "outputId": "561eeffd-291e-4c76-dc87-c086de4bdec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3655, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "res = VGG16(weights ='imagenet', include_top = False, input_shape = (224, 224, 3)) "
      ],
      "metadata": {
        "id": "tuEFKjeA2Zt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895d3078-1c38-4e78-f3a7-4fc4d9623ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import (Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input,GlobalAveragePooling2D,BatchNormalization)\n",
        "from tensorflow.keras import Sequential, Model\n",
        "\n",
        "res.trainable = False\n",
        "\n",
        "\n",
        "x= res.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "# x = Dropout(0.5)(x) \n",
        "x = Dense(512, activation ='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(256, activation ='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(4, activation ='softmax')(x)\n",
        "model = Model(res.input, x)\n",
        "\n",
        "model.compile(optimizer =tf.keras.optimizers.RMSprop(learning_rate=0.0001),  #'Adam'\n",
        "              loss =\"sparse_categorical_crossentropy\",  #sparse_categorical_crossentropy\n",
        "              metrics =[\"sparse_categorical_accuracy\"])  #sparse_categorical_accuracy\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DUr2emsv3BPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c59ca4-0bf4-4437-b9ea-761b6e462f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,114,820\n",
            "Trainable params: 397,572\n",
            "Non-trainable params: 14,717,248\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "RQ7h0zP36DTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "custom_early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=10, \n",
        "    min_delta=0.001, \n",
        "    mode='min'\n",
        ")"
      ],
      "metadata": {
        "id": "jne3wH0_8mA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgghist = model.fit(X_train,y_train, validation_data = (X_test,y_test), epochs = 50)"
      ],
      "metadata": {
        "id": "VrKlRZ30YxtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53263a9-69d2-4b8b-dee6-537be0fed743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "115/115 [==============================] - 40s 247ms/step - loss: 1.4562 - sparse_categorical_accuracy: 0.4057 - val_loss: 1.2260 - val_sparse_categorical_accuracy: 0.4907\n",
            "Epoch 2/50\n",
            "115/115 [==============================] - 25s 217ms/step - loss: 1.0928 - sparse_categorical_accuracy: 0.5535 - val_loss: 1.1340 - val_sparse_categorical_accuracy: 0.5463\n",
            "Epoch 3/50\n",
            "115/115 [==============================] - 28s 247ms/step - loss: 0.9160 - sparse_categorical_accuracy: 0.6317 - val_loss: 1.0884 - val_sparse_categorical_accuracy: 0.5648\n",
            "Epoch 4/50\n",
            "115/115 [==============================] - 28s 245ms/step - loss: 0.7736 - sparse_categorical_accuracy: 0.6952 - val_loss: 1.0478 - val_sparse_categorical_accuracy: 0.5916\n",
            "Epoch 5/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.7313 - val_loss: 1.0152 - val_sparse_categorical_accuracy: 0.6018\n",
            "Epoch 6/50\n",
            "115/115 [==============================] - 25s 222ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.7817 - val_loss: 0.9975 - val_sparse_categorical_accuracy: 0.6114\n",
            "Epoch 7/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.5481 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.9878 - val_sparse_categorical_accuracy: 0.6203\n",
            "Epoch 8/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.4834 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.9872 - val_sparse_categorical_accuracy: 0.6165\n",
            "Epoch 9/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.4236 - sparse_categorical_accuracy: 0.8643 - val_loss: 0.9888 - val_sparse_categorical_accuracy: 0.6228\n",
            "Epoch 10/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.9873 - val_sparse_categorical_accuracy: 0.6273\n",
            "Epoch 11/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8867 - val_loss: 0.9880 - val_sparse_categorical_accuracy: 0.6286\n",
            "Epoch 12/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.3236 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.9771 - val_sparse_categorical_accuracy: 0.6337\n",
            "Epoch 13/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.9827 - val_sparse_categorical_accuracy: 0.6426\n",
            "Epoch 14/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.2616 - sparse_categorical_accuracy: 0.9207 - val_loss: 0.9984 - val_sparse_categorical_accuracy: 0.6388\n",
            "Epoch 15/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.2318 - sparse_categorical_accuracy: 0.9346 - val_loss: 0.9931 - val_sparse_categorical_accuracy: 0.6484\n",
            "Epoch 16/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.2153 - sparse_categorical_accuracy: 0.9439 - val_loss: 1.0120 - val_sparse_categorical_accuracy: 0.6477\n",
            "Epoch 17/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.2026 - sparse_categorical_accuracy: 0.9390 - val_loss: 1.0150 - val_sparse_categorical_accuracy: 0.6509\n",
            "Epoch 18/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9458 - val_loss: 1.0654 - val_sparse_categorical_accuracy: 0.6375\n",
            "Epoch 19/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9568 - val_loss: 1.0476 - val_sparse_categorical_accuracy: 0.6420\n",
            "Epoch 20/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.1558 - sparse_categorical_accuracy: 0.9595 - val_loss: 1.0514 - val_sparse_categorical_accuracy: 0.6516\n",
            "Epoch 21/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.1412 - sparse_categorical_accuracy: 0.9614 - val_loss: 1.0664 - val_sparse_categorical_accuracy: 0.6528\n",
            "Epoch 22/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9661 - val_loss: 1.0773 - val_sparse_categorical_accuracy: 0.6420\n",
            "Epoch 23/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.1215 - sparse_categorical_accuracy: 0.9699 - val_loss: 1.0818 - val_sparse_categorical_accuracy: 0.6611\n",
            "Epoch 24/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.1144 - sparse_categorical_accuracy: 0.9705 - val_loss: 1.0906 - val_sparse_categorical_accuracy: 0.6592\n",
            "Epoch 25/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9743 - val_loss: 1.1089 - val_sparse_categorical_accuracy: 0.6496\n",
            "Epoch 26/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9748 - val_loss: 1.0884 - val_sparse_categorical_accuracy: 0.6650\n",
            "Epoch 27/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9762 - val_loss: 1.1307 - val_sparse_categorical_accuracy: 0.6496\n",
            "Epoch 28/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9817 - val_loss: 1.1108 - val_sparse_categorical_accuracy: 0.6599\n",
            "Epoch 29/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9773 - val_loss: 1.1547 - val_sparse_categorical_accuracy: 0.6554\n",
            "Epoch 30/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9825 - val_loss: 1.1399 - val_sparse_categorical_accuracy: 0.6592\n",
            "Epoch 31/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9806 - val_loss: 1.1827 - val_sparse_categorical_accuracy: 0.6541\n",
            "Epoch 32/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9839 - val_loss: 1.1751 - val_sparse_categorical_accuracy: 0.6592\n",
            "Epoch 33/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9841 - val_loss: 1.1568 - val_sparse_categorical_accuracy: 0.6662\n",
            "Epoch 34/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9814 - val_loss: 1.1787 - val_sparse_categorical_accuracy: 0.6599\n",
            "Epoch 35/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.1974 - val_sparse_categorical_accuracy: 0.6675\n",
            "Epoch 36/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9863 - val_loss: 1.2323 - val_sparse_categorical_accuracy: 0.6694\n",
            "Epoch 37/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9880 - val_loss: 1.2231 - val_sparse_categorical_accuracy: 0.6701\n",
            "Epoch 38/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.2784 - val_sparse_categorical_accuracy: 0.6516\n",
            "Epoch 39/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9885 - val_loss: 1.2550 - val_sparse_categorical_accuracy: 0.6637\n",
            "Epoch 40/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9855 - val_loss: 1.2952 - val_sparse_categorical_accuracy: 0.6496\n",
            "Epoch 41/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0487 - sparse_categorical_accuracy: 0.9877 - val_loss: 1.3182 - val_sparse_categorical_accuracy: 0.6490\n",
            "Epoch 42/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9885 - val_loss: 1.2582 - val_sparse_categorical_accuracy: 0.6662\n",
            "Epoch 43/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.2701 - val_sparse_categorical_accuracy: 0.6611\n",
            "Epoch 44/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9899 - val_loss: 1.3007 - val_sparse_categorical_accuracy: 0.6631\n",
            "Epoch 45/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9893 - val_loss: 1.2846 - val_sparse_categorical_accuracy: 0.6573\n",
            "Epoch 46/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.3077 - val_sparse_categorical_accuracy: 0.6579\n",
            "Epoch 47/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0419 - sparse_categorical_accuracy: 0.9888 - val_loss: 1.2913 - val_sparse_categorical_accuracy: 0.6643\n",
            "Epoch 48/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0408 - sparse_categorical_accuracy: 0.9885 - val_loss: 1.3152 - val_sparse_categorical_accuracy: 0.6637\n",
            "Epoch 49/50\n",
            "115/115 [==============================] - 25s 220ms/step - loss: 0.0337 - sparse_categorical_accuracy: 0.9918 - val_loss: 1.3302 - val_sparse_categorical_accuracy: 0.6554\n",
            "Epoch 50/50\n",
            "115/115 [==============================] - 25s 221ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9915 - val_loss: 1.3102 - val_sparse_categorical_accuracy: 0.6662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=model.predict(X_test).argmax(axis=1)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LmYySWvk0b-",
        "outputId": "6ef65c9d-50f0-454b-a3bc-2510487c1aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 7s 149ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6662412252712189"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "duO2rrshk37s",
        "outputId": "6c2f482c-7dd3-4b49-d4b7-3e931f9534cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plEnmX271omg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "base_model=InceptionV3(include_top=False, weights='imagenet',input_shape=(224,224,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk7n0wuyyc3p",
        "outputId": "16357a01-55d1-417f-b6f1-d72183e6a454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in base_model.layers:\n",
        "    i.trainable=False   "
      ],
      "metadata": {
        "id": "eEVLZ35lzaIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Flatten()(x)\n",
        "x = Dense(128, activation ='relu')(x)\n",
        "#x=Dropout(0.5)(x)\n",
        "x = Dense(64, activation ='relu')(x)\n",
        "pred=Dense(4,activation='softmax')(x)\n",
        "model=Model(inputs=base_model.input,outputs=pred)"
      ],
      "metadata": {
        "id": "19z5t2L2zed_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "1gJd8SeGzlUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qWJURxRzpfY",
        "outputId": "3befdadc-f0da-4d77-a4f1-34c8fb7e8224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          262272      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            260         ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,073,572\n",
            "Trainable params: 270,788\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InceptionVRHist = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dRPJkFBztK8",
        "outputId": "6406fa84-f08f-4d5e-b7fa-63769bc5fb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 1.0396 - accuracy: 0.5450 - val_loss: 1.3607 - val_accuracy: 0.4314\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9523 - accuracy: 0.5787 - val_loss: 1.3674 - val_accuracy: 0.4288\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.9784 - accuracy: 0.5724 - val_loss: 1.2912 - val_accuracy: 0.4505\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - 12s 102ms/step - loss: 0.9305 - accuracy: 0.5899 - val_loss: 1.3353 - val_accuracy: 0.4365\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.9774 - accuracy: 0.5614 - val_loss: 1.3339 - val_accuracy: 0.4448\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.9426 - accuracy: 0.5929 - val_loss: 1.4587 - val_accuracy: 0.4148\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9599 - accuracy: 0.5885 - val_loss: 1.3795 - val_accuracy: 0.4046\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - 11s 98ms/step - loss: 1.0100 - accuracy: 0.5483 - val_loss: 1.4731 - val_accuracy: 0.4135\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9804 - accuracy: 0.5740 - val_loss: 1.3645 - val_accuracy: 0.4601\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9730 - accuracy: 0.5746 - val_loss: 1.3624 - val_accuracy: 0.4646\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9593 - accuracy: 0.5748 - val_loss: 1.4308 - val_accuracy: 0.4467\n",
            "Epoch 12/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 1.0106 - accuracy: 0.5595 - val_loss: 1.5775 - val_accuracy: 0.4103\n",
            "Epoch 13/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9678 - accuracy: 0.5762 - val_loss: 1.3564 - val_accuracy: 0.4601\n",
            "Epoch 14/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9126 - accuracy: 0.6025 - val_loss: 1.3850 - val_accuracy: 0.4525\n",
            "Epoch 15/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9062 - accuracy: 0.6044 - val_loss: 1.4189 - val_accuracy: 0.4403\n",
            "Epoch 16/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9216 - accuracy: 0.5844 - val_loss: 1.5353 - val_accuracy: 0.4301\n",
            "Epoch 17/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.9265 - accuracy: 0.6057 - val_loss: 1.4224 - val_accuracy: 0.4703\n",
            "Epoch 18/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9099 - accuracy: 0.6057 - val_loss: 1.4446 - val_accuracy: 0.4493\n",
            "Epoch 19/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8821 - accuracy: 0.6101 - val_loss: 1.3974 - val_accuracy: 0.4556\n",
            "Epoch 20/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8796 - accuracy: 0.6172 - val_loss: 1.4674 - val_accuracy: 0.4186\n",
            "Epoch 21/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9252 - accuracy: 0.5984 - val_loss: 1.5328 - val_accuracy: 0.4071\n",
            "Epoch 22/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.9489 - accuracy: 0.5828 - val_loss: 1.4608 - val_accuracy: 0.4480\n",
            "Epoch 23/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8802 - accuracy: 0.6238 - val_loss: 1.5108 - val_accuracy: 0.4403\n",
            "Epoch 24/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8539 - accuracy: 0.6361 - val_loss: 1.4021 - val_accuracy: 0.4601\n",
            "Epoch 25/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8501 - accuracy: 0.6345 - val_loss: 1.4574 - val_accuracy: 0.4505\n",
            "Epoch 26/100\n",
            "115/115 [==============================] - 13s 115ms/step - loss: 0.8959 - accuracy: 0.6164 - val_loss: 1.4752 - val_accuracy: 0.4633\n",
            "Epoch 27/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8518 - accuracy: 0.6353 - val_loss: 1.5565 - val_accuracy: 0.4620\n",
            "Epoch 28/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8424 - accuracy: 0.6367 - val_loss: 1.5400 - val_accuracy: 0.4371\n",
            "Epoch 29/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8393 - accuracy: 0.6369 - val_loss: 1.4980 - val_accuracy: 0.4588\n",
            "Epoch 30/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8849 - accuracy: 0.6161 - val_loss: 1.4664 - val_accuracy: 0.4531\n",
            "Epoch 31/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8431 - accuracy: 0.6438 - val_loss: 1.4443 - val_accuracy: 0.4639\n",
            "Epoch 32/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8249 - accuracy: 0.6487 - val_loss: 1.4605 - val_accuracy: 0.4531\n",
            "Epoch 33/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8260 - accuracy: 0.6449 - val_loss: 1.4267 - val_accuracy: 0.4582\n",
            "Epoch 34/100\n",
            "115/115 [==============================] - 13s 115ms/step - loss: 0.7912 - accuracy: 0.6624 - val_loss: 1.5029 - val_accuracy: 0.4429\n",
            "Epoch 35/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8087 - accuracy: 0.6610 - val_loss: 1.6341 - val_accuracy: 0.4301\n",
            "Epoch 36/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8223 - accuracy: 0.6498 - val_loss: 1.4875 - val_accuracy: 0.4352\n",
            "Epoch 37/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8029 - accuracy: 0.6550 - val_loss: 1.6179 - val_accuracy: 0.4442\n",
            "Epoch 38/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.8021 - accuracy: 0.6610 - val_loss: 1.5797 - val_accuracy: 0.4614\n",
            "Epoch 39/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7936 - accuracy: 0.6591 - val_loss: 1.5777 - val_accuracy: 0.4467\n",
            "Epoch 40/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7482 - accuracy: 0.6859 - val_loss: 1.5647 - val_accuracy: 0.4480\n",
            "Epoch 41/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7665 - accuracy: 0.6709 - val_loss: 1.6466 - val_accuracy: 0.4569\n",
            "Epoch 42/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7706 - accuracy: 0.6673 - val_loss: 1.6813 - val_accuracy: 0.4512\n",
            "Epoch 43/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7724 - accuracy: 0.6761 - val_loss: 1.6144 - val_accuracy: 0.4601\n",
            "Epoch 44/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7906 - accuracy: 0.6681 - val_loss: 1.6607 - val_accuracy: 0.4614\n",
            "Epoch 45/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7633 - accuracy: 0.6689 - val_loss: 1.5636 - val_accuracy: 0.4620\n",
            "Epoch 46/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7361 - accuracy: 0.6900 - val_loss: 1.6614 - val_accuracy: 0.4518\n",
            "Epoch 47/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7619 - accuracy: 0.6804 - val_loss: 1.5984 - val_accuracy: 0.4595\n",
            "Epoch 48/100\n",
            "115/115 [==============================] - 12s 101ms/step - loss: 0.7681 - accuracy: 0.6673 - val_loss: 1.7363 - val_accuracy: 0.4486\n",
            "Epoch 49/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7541 - accuracy: 0.6785 - val_loss: 1.6677 - val_accuracy: 0.4454\n",
            "Epoch 50/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7261 - accuracy: 0.6936 - val_loss: 1.8646 - val_accuracy: 0.4288\n",
            "Epoch 51/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7652 - accuracy: 0.6750 - val_loss: 1.5815 - val_accuracy: 0.4544\n",
            "Epoch 52/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7447 - accuracy: 0.6878 - val_loss: 1.6148 - val_accuracy: 0.4620\n",
            "Epoch 53/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6804 - accuracy: 0.7097 - val_loss: 1.7120 - val_accuracy: 0.4378\n",
            "Epoch 54/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7381 - accuracy: 0.6933 - val_loss: 1.6712 - val_accuracy: 0.4416\n",
            "Epoch 55/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7438 - accuracy: 0.6810 - val_loss: 1.6364 - val_accuracy: 0.4556\n",
            "Epoch 56/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7625 - accuracy: 0.6706 - val_loss: 1.7297 - val_accuracy: 0.4614\n",
            "Epoch 57/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7327 - accuracy: 0.6903 - val_loss: 1.6709 - val_accuracy: 0.4595\n",
            "Epoch 58/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7140 - accuracy: 0.6971 - val_loss: 1.6457 - val_accuracy: 0.4671\n",
            "Epoch 59/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7028 - accuracy: 0.7045 - val_loss: 1.8788 - val_accuracy: 0.4518\n",
            "Epoch 60/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7258 - accuracy: 0.6897 - val_loss: 1.6699 - val_accuracy: 0.4614\n",
            "Epoch 61/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6820 - accuracy: 0.7133 - val_loss: 1.8533 - val_accuracy: 0.4493\n",
            "Epoch 62/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6681 - accuracy: 0.7212 - val_loss: 1.7826 - val_accuracy: 0.4767\n",
            "Epoch 63/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6815 - accuracy: 0.7097 - val_loss: 1.8335 - val_accuracy: 0.4620\n",
            "Epoch 64/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6964 - accuracy: 0.7100 - val_loss: 1.8002 - val_accuracy: 0.4710\n",
            "Epoch 65/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6566 - accuracy: 0.7250 - val_loss: 1.9457 - val_accuracy: 0.4748\n",
            "Epoch 66/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6619 - accuracy: 0.7223 - val_loss: 1.9821 - val_accuracy: 0.4340\n",
            "Epoch 67/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8580 - accuracy: 0.6446 - val_loss: 1.6563 - val_accuracy: 0.4212\n",
            "Epoch 68/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.8362 - accuracy: 0.6509 - val_loss: 1.6622 - val_accuracy: 0.4576\n",
            "Epoch 69/100\n",
            "115/115 [==============================] - 13s 116ms/step - loss: 0.6883 - accuracy: 0.7094 - val_loss: 1.8938 - val_accuracy: 0.4588\n",
            "Epoch 70/100\n",
            "115/115 [==============================] - 12s 100ms/step - loss: 0.6610 - accuracy: 0.7209 - val_loss: 1.8799 - val_accuracy: 0.4831\n",
            "Epoch 71/100\n",
            "115/115 [==============================] - 12s 102ms/step - loss: 0.6346 - accuracy: 0.7357 - val_loss: 1.7955 - val_accuracy: 0.4684\n",
            "Epoch 72/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6671 - accuracy: 0.7226 - val_loss: 2.0696 - val_accuracy: 0.4550\n",
            "Epoch 73/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6610 - accuracy: 0.7196 - val_loss: 1.8648 - val_accuracy: 0.4652\n",
            "Epoch 74/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6410 - accuracy: 0.7291 - val_loss: 1.8842 - val_accuracy: 0.4518\n",
            "Epoch 75/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6506 - accuracy: 0.7256 - val_loss: 1.9271 - val_accuracy: 0.4480\n",
            "Epoch 76/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.7235 - accuracy: 0.6971 - val_loss: 1.9690 - val_accuracy: 0.4601\n",
            "Epoch 77/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6579 - accuracy: 0.7275 - val_loss: 1.7907 - val_accuracy: 0.4754\n",
            "Epoch 78/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6295 - accuracy: 0.7401 - val_loss: 1.9904 - val_accuracy: 0.4582\n",
            "Epoch 79/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6172 - accuracy: 0.7420 - val_loss: 2.1597 - val_accuracy: 0.4454\n",
            "Epoch 80/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6462 - accuracy: 0.7297 - val_loss: 1.8168 - val_accuracy: 0.4582\n",
            "Epoch 81/100\n",
            "115/115 [==============================] - 13s 115ms/step - loss: 0.6080 - accuracy: 0.7486 - val_loss: 1.9784 - val_accuracy: 0.4697\n",
            "Epoch 82/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6079 - accuracy: 0.7508 - val_loss: 1.9315 - val_accuracy: 0.4773\n",
            "Epoch 83/100\n",
            "115/115 [==============================] - 13s 115ms/step - loss: 0.6245 - accuracy: 0.7294 - val_loss: 2.1070 - val_accuracy: 0.4556\n",
            "Epoch 84/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6773 - accuracy: 0.7248 - val_loss: 1.9394 - val_accuracy: 0.4690\n",
            "Epoch 85/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6305 - accuracy: 0.7415 - val_loss: 2.0872 - val_accuracy: 0.4582\n",
            "Epoch 86/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6303 - accuracy: 0.7371 - val_loss: 1.9169 - val_accuracy: 0.4486\n",
            "Epoch 87/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6295 - accuracy: 0.7390 - val_loss: 2.1294 - val_accuracy: 0.4416\n",
            "Epoch 88/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6246 - accuracy: 0.7368 - val_loss: 2.1656 - val_accuracy: 0.4582\n",
            "Epoch 89/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.7147 - accuracy: 0.6985 - val_loss: 2.1447 - val_accuracy: 0.4486\n",
            "Epoch 90/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6319 - accuracy: 0.7338 - val_loss: 2.2962 - val_accuracy: 0.4448\n",
            "Epoch 91/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6067 - accuracy: 0.7475 - val_loss: 2.0277 - val_accuracy: 0.4518\n",
            "Epoch 92/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.5716 - accuracy: 0.7653 - val_loss: 2.0794 - val_accuracy: 0.4608\n",
            "Epoch 93/100\n",
            "115/115 [==============================] - 12s 100ms/step - loss: 0.5779 - accuracy: 0.7587 - val_loss: 2.0994 - val_accuracy: 0.4518\n",
            "Epoch 94/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6093 - accuracy: 0.7508 - val_loss: 2.1138 - val_accuracy: 0.4614\n",
            "Epoch 95/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6503 - accuracy: 0.7384 - val_loss: 2.0375 - val_accuracy: 0.4505\n",
            "Epoch 96/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.6041 - accuracy: 0.7486 - val_loss: 1.9877 - val_accuracy: 0.4761\n",
            "Epoch 97/100\n",
            "115/115 [==============================] - 13s 115ms/step - loss: 0.5627 - accuracy: 0.7603 - val_loss: 2.4384 - val_accuracy: 0.4493\n",
            "Epoch 98/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.6243 - accuracy: 0.7450 - val_loss: 2.2177 - val_accuracy: 0.4576\n",
            "Epoch 99/100\n",
            "115/115 [==============================] - 11s 99ms/step - loss: 0.5526 - accuracy: 0.7732 - val_loss: 2.0659 - val_accuracy: 0.4627\n",
            "Epoch 100/100\n",
            "115/115 [==============================] - 11s 100ms/step - loss: 0.5863 - accuracy: 0.7560 - val_loss: 2.0485 - val_accuracy: 0.4499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred=model.predict(X_test).argmax(axis=1)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r9ZAeVX1uKb",
        "outputId": "234cf18e-9b74-4540-efe3-ebcc2e536b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 3s 66ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44990427568602426"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lr-RAMI41yQf",
        "outputId": "b34f223c-c86e-45a6-d37f-ebffaaf66173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fn48c+TfSUkBMJOUDYRFDAqCAJiVVwqaq1rFbeirWu1+lNsa63aaq271YrL16XulVZEBVFREGXfZCeyQ1gSkpB9m+f3x9xgEJLMJJncmeF5v173lZk7d+59biZ55px77jlHVBVjjAlHEW4HYIwxgWIJzhgTtizBGWPCliU4Y0zYsgRnjAlbUW4HUFdkQqJGt01zO4wWF7urzO0QAsaTFOd2CAERURSen1mZllCp5dKcfZxxSqLm7a3xadtFyyumq+rY5hyvOYIqwUW3TSPzutvdDqPF9Xjqe7dDCJiKYX3dDiEgYmetcDuEgJhb/kmz95G3t4b507v7tG1kp/XpzT5gMwRVgjPGBD8FPHjcDsMnluCMMX5RlCr1rYrqNktwxhi/WQnOGBOWFKUmRLp4WoIzxvjNgyU4Y0wYUqDGEpwxJlyFSgnOejIYY/yiQJWqT0tDRKSbiMwUkVUislJEbnXW/1lEtovIUmc5q8577hGRbBFZKyJnNBarleCMMX5RtKWqqNXAHaq6WESSgUUiMsN57QlV/UfdjUWkP3AJcDTQGfhcRPqo1n/PiiU4Y4x/FGpaIL+pag6Q4zwuEpHVQJcG3jIOeEdVK4CNIpINnAB8V98brIpqjPGLtyeDbwuQLiIL6ywTDrVPEckEBgPznFU3ichyEXlFRFKddV2ArXXeto2GE6KV4Iwx/hJq8Lm/fq6qZjW4N5Ek4APgNlXdJyLPAw/gzaUPAI8B1zQlUktwxhi/eBsZmjUgyX4iEo03ub2pqpMBVHVXnddfBKY6T7cD3eq8vauzrl5WRTXG+MV7H5z4tDRERAR4GVitqo/XWd+pzmbnA7VDu0wBLhGRWBHpCfQG5jd0DCvBGWP85mmZEtxw4ArgexFZ6qybCFwqIoPw5tJNwPUAqrpSRN4DVuFtgb2xoRZUsARnjPFTbQmu2ftR/QYOuaN6B61T1YeAh3w9hiU4Y4xfFKEmRK5uWYIzxvithaqoAWcJzhjjF0Wo1Ei3w/CJJThjjF+8N/paFdUYE6ZaopGhNYRlgnvwlJmM6rGJvWXxjHv3EgB+P+xbRmdupsoTwdbCFO798hSKKmOJjqjhz6O+5ugOe/Co8LdvhrNgR4O9P4JGdIyHR99cTnSMh8hI+GZ6O/79TA+OHVrAdXdtJCpayV6ZxBP39sZTExp/kLUuPH0FZ41aiyps3JbGIy+fTLuUMv74m5m0SSpn3aZ0/jZpFNU1oVFVAufzencV0TFKZKTyzbQ0/v1kV0AZf8c2Rpy1F08NfPxmBlNe6+h2uPVSFWrUSnCIyFjgKSASeElVHw7k8Wr9d01f3vx+AA+f+sX+dd9u68YTc4dSoxHcPvQ7fj1kMY/PHcaF/VcDcN67F5MWX8oLZ3/MRf+5EA2Bb6iqSuHu8QMpL40kMsrDP95azqJvUrnj4XXcc9VAtm+K54pbNvOz83fx2X+C9x/mp9LblnD+aSu5euIvqKyK4k+//ZIxJ27gxGO28Z/PjmbmvCO5bfwczhq5jikzj3I7XJ9VVQp3X37Uj5/Xe6tY+FUK3XqVk96pkgk/OwZVIaVdlduhNsoTAv8fEMCeDCISCfwTOBPoj/fmvf6BOl5di3I6U1gRe8C6b7d22/+ts2xXBh2TSgA4MnUvc7d7S2x7yxIoqoxlQIfdrRFmCxDKS70lmKgoJSpK8dQI1VURbN8UD8DiOW0ZcXqem0E2SWSEEhtTQ0SEh9iYavIKEhh81A6+XtATgM++6cXwIZtdjtJfB39eqsLZl+/irWe6oE7LZGFetJtBNsrbyBDl0+K2QEZwApCtqhsAROQdvMOdrArgMX1ywVFrmJbdC4C1eemMydzEJ+t70zGpmP7t99AxqZjvd2e4HKVvIiKUpycvpXP3Mqa+1Ym1y5OIiFR6Dyhi/YpkRozNJb1jhdth+iW3IJH3pg3gncfeoaIyioUru7BuUzrFpTF4PN4vqT35iaSnlrgcqf8iIpSnp6ygc49ypv47g7XLkujUvYJRZ+cx7Ix8CvOi+NdfMtmxKc7tUOtljQxehxra5MQAHs8n1x+3iBpPBB+t6w3A5NX9OCI1n/d/+R92FCWzdGdHPCFyfQHA4xFuOm8wicnV/PGfq+nRu5SHb+/LhHs2Eh3jYfGcVDye0KhO1EpKqGD44C1cdudFFJfGct+NX3DCwG1uh9UiPB7hpnMGej+vf62jR59SomM8VFZEcOu4AZx0xl5+98gG7ry4VSo7TVZj98H5xhkfagJAVEpqI1s3z3l91zCqx2aumfJzanuI1GgEj8wZvn+bNy+YzKaClIDGEQglRVEsn5dC1sn5fPBKV+68/BgAhgzPp0tmmcvR+ee4o3eQk5tMYZG3mj17YSYDeu8iKaGSiAgPHk8E7VNLyM1PdDnSpispimL53DZkjSwkd2cMc6Z7//a/nZ7K7X/f4HJ0DQulngyBjNKnoU1UdZKqZqlqVmRC4P5gR3TbwrWDl3LjJ2dSXv3jNY64qCrio7wXdYd13UqNJ4If8tMCFkdLSkmtIjG5GoCY2BoGn1TA1g0JpKRVAhAd7eGXv97GJ++ETgMDwK68RPofuZvYmGpAGdJ/B5t3tGXpmk6MOn4jAKePyGbOku7uBuqnlLS6n5eHwSP2sXVDHN/NSOXYYfsAGHhiEds3Bm/1tJZHI3xa3BbIEtwCoLczrMl2vGOpXxbA4+336GkzOKHzDtrGlfPlla/z7ILjmTBkMdGRNbx87keAt6Hh/q9HkRZfxovnTMWDsLs4kbs/P7U1QmwRqR0q+f3D64iIVERg9rR05n+VxrV3beSE0XuJiICP3+7Isrlt3Q7VL2s2dODrBT154f7/UVMjZG9px9Sv+jF3WTf++JuZXHPBIrK3tOPTWX3dDtUvqR2q+P2jP/z4eX2SxvwvU1m5IJm7nvyB867ZSXlJJE/e3dPtUBvk7WzvfvLyhWgAZ6h2ZsN5Eu9tIq84IwHUK65zN8287vaAxeOWHk9973YIAVMxLLSSjK9iZ61ofKMQNLf8Ewo9ec26gNZzYJL+efIxPm17VZ/vFjU2om8gBfQanKp+QgNDnxhjQo8qdqOvMSZcScjc6GsJzhjjF8VKcMaYMBYqjQyW4IwxflHEBrw0xoQn77SBoZE6QiNKY0wQ8WviZ1dZgjPG+EUhKHop+MISnDHGb1aCM8aEJVWxEpwxJjx5GxlCY6h4S3DGGD/ZnAzGmDDlbWSwa3DGmDBlPRmMMWHJejIYY8KaTTpjjAlLqlDlsQRnjAlD3iqqJThjTJiyngzGmLBkt4kYY8KYVVGNMWHM5mRogpicEro9+K3bYbS4T3csdTuEgOn//EC3QwiI7nt7uR1CQOjK2ObvQ6HKY31RjTFhKJRu9A2NirQxJqh4nKkDG1saIiLdRGSmiKwSkZUicquzPk1EZojIeudnqrNeRORpEckWkeUiMqSxOC3BGWP8UtuK6svSiGrgDlXtDwwFbhSR/sDdwBeq2hv4wnkOcCbQ21kmAM83dgBLcMYYv3k0wqelIaqao6qLncdFwGqgCzAOeM3Z7DXgPOfxOOB19ZoLtBWRTg0dw67BGWP8oipU+36bSLqILKzzfJKqTvrpRiKSCQwG5gEZqprjvLQTyHAedwG21nnbNmddDvWwBGeM8ZsfjQy5qprV0AYikgR8ANymqvtEfty3qqqIaFPjtARnjPFLS/ZkEJFovMntTVWd7KzeJSKdVDXHqYLudtZvB7rVeXtXZ1297BqcMcZvLdHIIN6i2svAalV9vM5LU4DxzuPxwId11l/ptKYOBQrrVGUPyUpwxhi/tOB9cMOBK4DvRaT2bviJwMPAeyJyLbAZuMh57RPgLCAbKAWubuwAluCMMX5ria5aqvoN1LujUw+xvQI3+nMMS3DGGL+oQrUNeGmMCVeh0lXLEpwxxi+h1BfVEpwxxm9qCc4YE65sPDhjTFhStWtwxpiwJdRYK6oxJlzZNThjTFiyWbWMMeFLvdfhQoElOGOM36wV1RgTltQaGYwx4cyqqEEiOtbDY5OziY5RIqOU2R+35Y1/dCSjWwUTn99Cm9Rq1n8fz99v7k51VXB/K+3eHs2jt3anYE80iHLWr/I4/7pcAD58OZ0pr6YTEamceOo+rvtjDmuWJPDUnd7xARW44o6dDD+z0MUzqN+Do2cyKnMTe8viGffuJQDcfPx8xvTciKqQVxbPxC/HsKc0EVAmDp/DyB6bKauOYuKXY1id297dE/BRYmIlt900l8wehajCE08PZfXa9px79lp+fvY6PB5h/sLOvPxqoxNGueqwb0UVkVeAc4DdqjogUMdpTFWFcNcvj6S8NJLIKOXx/2Wz4MtkfjFhD5NfTOfrD1O55eFtjL10L1NfT3crTJ9ERikT/rSD3seUUVocwU1j+zBkZBH5e6L5dnoKz3++lphYpSDX+7Fm9i3j2WlriYyCvF1R/OZnfRl6WiGRQfi19t+1fXlzxQAePvWL/eteWTqIZxacAMCvBi7nt1kLuX/WKEZ230KPtgWMfesyjsnYxX0jZ3HJ5F+4Fbpfbvj1QhYt7sxDj4wkKqqG2Ngajhm4k2EnbuO3t5xFVXUkKSnlbofZINXQSXCBLLK8CowN4P59JJSXemfhjopWIqMVVTh2RDGzp7YFYMb7qQwbG5wlm7raZVTT+5gyABKSPHTrVUFuTjRTX2/HxTftIibWW29om14NQFyC7k9mVRURSBD/TS7K6UxhxYGzrpdUxex/HB9VTW2taEzmJj5c2xcQlu/qSHJsBekJJa0XbBMlJFQy8OjdTJtxJADV1ZGUlMRwzpnree+D/lRVe/9OCwvj3AzTJy00bWDABey7XFVnOTPluC4iQnl2+jo6Z1by0avtyNkcS0lhJJ4a7weQmxNNesdql6P0z86tMfywIp5+Q0p56YEurJiXxKuPdCImVvn1n7bTd5A3Ea5ZnMBjt3dj97YY7npmS1CW3hpy6wnzOLfvWoorY7jqw3EAdEgsYWdx0v5tdhUnkZFYQm5polth+qRjRjGFhXHccetcevbMJzs7jedfzKJL5yKO7r+H8b9aRmVVJC+9MoR12e3cDrdBoXINzvWLTiIyQUQWisjCKioCcgyPR/jtaX25/Lj+9B1USrdewV0FaExZSQQPXJfJDX/ZTmKyh5oaKCqI5Kmp67nujzt46PrM/X+A/YaU8uJXa3nm03W880wHKsvd/1b1x1PzT+TUN65k6ro+XD7we7fDaZbISKXXkXuZ+mlvbrrtLMrLo7j4wpVERnpITq7gtjvP4KX/G8zE/zcbCN4MoggeT4RPi9tcj0BVJ6lqlqpmRRPb+BuaoWRfJMu+TeKo40pJTKkhItL7R5TeqYrcnaFRtKmuggeuy2TMBfmMOMtbrU7vVMXwswoRgX6DS4mIgMK9kQe8r3vvCuITPWxaG/zVn0OZur43px2xAYDdJYl0TCre/1pGUjG7SoK79AaQm5tAbm4Ca9d5r/XO/rY7vY7YS25eAnO+6wYI69an4/EIKW0C82XfUtTHxW2uJ7hAS0mrJrFNDQAxcR6GjCxm6/o4ls1J4uRzCgA47Zf5fDc9xc0wfaIKj9/RnW69K/jF9Xv2rz9pbCHL5nirbNt+iKWqUkhJq2HnlhhqnJr3rm3RbM2OI6NrpRuhN0mPlIL9j8dkbmJDfioAX27KZFzftYByTMZOiipig756CpBfEM+e3AS6dtkHwOBjd7Jlawrfzu3KsQN3AdCl8z6iozwU7gvsl32zOI0MvixuC41iSzOkZVTx+6e2EBEBEREw66MU5n3ehs3rYpn4/Gauumsn2Svimf52mtuhNmrl/ES++E8aPY8q4zc/6wvA1ffs4IxL9vL47d2YcEpfoqOVO5/aggismJ/Iu8/2JCrKex3y5r9uI6VdjctncWiP/mwGJ3TeQdu4cr684nWeXXA8I3tspmfbAjwq7ChK5v5ZIwGYtaU7I3tsZtplb1FeHcW9M09xOXrfPTcpi7tun0N0tIecnUk8/tRQyiuiuP2WufzrmalUV0fwj6eGUf9cLEEiGIpnPhAN0NVCEXkbGA2kA7uA+1T15Ybe00bS9EQ5aDKdkDd9x9LGNwpR/Z//rdshBET3T/e5HUJAzF35AvtKdjQre8Yd2UW7Pfwbn7bNvuiPixqb2T6Q6i3BicgzNJCnVfWWhnasqpc2Iy5jTJBSvA13oaChKurCVovCGBM6FAiC62u+qDfBqeprdZ+LSIKqlgY+JGNMsAub++BEZJiIrALWOM+PFZHnAh6ZMSZ4hch9Ir7cJvIkcAaQB6Cqy4CRgQzKGBPMfLtFJGRuE1HVrXJgR8bgvNfAGNM6gqB05gtfEtxWETkJUBGJBm4FVgc2LGNM0FLQEGlF9aWKegNwI9AF2AEMcp4bYw5b4uPirkZLcKqaC1zeCrEYY0JFiFRRfWlFPUJEPhKRPSKyW0Q+FJEjWiM4Y0yQCqNW1LeA94BOQGfgfeDtQAZljAlitTf6+rK4zJcEl6Cqb6hqtbP8GwjNMXeMMS1C1bfFbQ31Ra0dXuNTEbkbeAdv7r4Y+KQVYjPGBKsQaUVtqJFhEd6EVnsm19d5TYF7AhWUMSa4SRCUznzRUF/Unq0ZiDEmRARJA4IvfOrJICIDgP7Uufamqq8HKihjTDALjgYEX/hym8h9wDPOcgrwd+DcAMdljAlmLXSbiIi84tx+tqLOuj+LyHYRWeosZ9V57R4RyRaRtSJyRmP796UV9ULgVGCnql4NHAsE/wQGxpjA8fi4NO5VDj1/8hOqOshZPgEQkf7AJcDRznueE5HIQ7x3P18SXJmqeoBqEWkD7Aa6+RS6MSb8tOB9cKo6C9jr45HHAe+oaoWqbgSygRMaeoMvCW6hiLQFXsTbsroY+M7HgIwxYUjUtwVIr5332Fkm+HiIm0RkuVOFTXXWdQG21tlmm7OuXr70Ra2dVeRfIjINaKOqy30M0hgTjnxvRc1twqQzzwMPOEd5AHgMuMbPfQAN3+g7pKHXVHVxUw5ojDENUdVdtY9F5EVgqvN0OwdeHuvqrKtXQyW4xxqKARjTcJj+k9gYInuEXz/+rPuGuR1CwFSMKnM7hMCYGiI3erkkkDf6ikgnVc1xnp4P1LawTgHeEpHH8faL7w3Mb2hfDd3oGzqz6RpjWo/SYl216s6fLCLbgPuA0SIyyDnSJpxeVKq6UkTeA1YB1cCNqtrg6OJhP7O9MSYAWqgEV8/8yfVOEK+qDwEP+bp/S3DGGL+FfF9UY4ypV4gkOF+6aomI/EpE/uQ87y4iDd5cZ4wJc2E0ou9zwDCgtq5cBPwzYBEZY4Karzf5BkM11pcq6omqOkRElgCoar6IxAQ4LmNMMAuDAS9rVTkdWhVARNrjazdaY0xYCobSmS98qaI+DfwX6CAiDwHfAH8NaFTGmOAWItfgfOmL+qaILMI7ZJIA56mqzWxvzOEqSK6v+aLRBCci3YFS4KO661R1SyADM8YEsXBJcMDH/Dj5TBzQE1iLd9A5Y8xhSELkKrwvVdSBdZ87o4z8tp7NjTEmaPjdk0FVF4vIiYEIxhgTIsKliioit9d5GgEMAXYELCJjTHALp0YGILnO42q81+Q+CEw4xpiQEA4JzrnBN1lVf99K8RhjQkGoJzgRiVLVahEZ3poBGWOCmxAerajz8V5vWyoiU4D3gZLaF1V1coBjM8YEozC7BhcH5OGdg6H2fjgFLMEZc7gKgwTXwWlBXcGPia1WiJyeMSYgQiQDNJTgIoEkDkxstULk9IwxgRAOVdQcVf1Lq0USQP/3znTKyqKoqRE8NcKt15/C5Vet5oxzNlFYEAvAay/2Z+G8ji5H2rg/jZvJiD6byS+J5+LnLgagTXw5f/vlDDq1LSKnIJm73zudovJYrhi+lLED1wMQFeEhs30Bp/19PPvK4tw8hUPqMGkzCUv3UdMmiq0PH7V/fcpne0iZsQeNEEoHtSHv0i4kzdlL6se7928Ts7WMrQ/2pbJHghuh+yUxsZLbbplHZo9CFHjiyRNZvaY9ABecv5oJ1y3hoksvYN++4PuMDhAGCa5ZI9qJSDfgdSAD769jkqo+1Zx9Nsfdt41gX2HsAev+934vJr/b26WImuajpX15d/4A/nL+l/vXXTViCfM3dOW1bwYzfsQSrjp5Cc/MGMobcwbxxpxBAJzcZxOXDVselMkNYN/IdhSe1p4OL2zevy5+VRGJiwrY8td+EB1BZGEVAMXD0ygengZ4k1unJzaERHIDuGHCIhYt6sRDfzuZqKgaYmO9s96lp5dw3OAcdu0OgfPQ0GlFbWg8uFObue9q4A5V7Q8MBW4Ukf7N3Odhb8nmzuwrOzBRj+q3ialL+wAwdWkfRvfbeND7zhiYzfQVvVolxqYo75dETVLkAevafJ5L/s8zINr7Z1qTEn3Q+5K+zadoaGqrxNhcCQmVDBywm2mfHQlAdXUkJSXewbGv//ViXvq/waChMVJuyI8Hp6p7m7NjZ2bqHOdxkYisBrrgnbS1VSnw4D/moCp8+lEm0z7qCcDPz9/AqWdsYf3atrz0z4EUF4fmSOxpiWXkFScCkFecQFrigbPNx0ZXMazXVv7+yQg3wmuymJ0VxK8tod37OWh0BLmXdqbiyMQDtkmel0/O745wKUL/dOxYQmFhLHf8bi49exaQnZ3G8y8cx+DBO8nLi2fjxtBI1BAe1+BajIhkAoOBeYd4bQIwASAuqk1Ajn/nTSPJy40npW0FDz32Dds2J/Pxhz15+/V+qMIV167iuhu/58lHjgvI8VuXHPTFObLPZpZt7Ri01dN6eZSI4mq2/bkPsRtK6fjsJjY/3h/EW8qJzS7BExNBZbd4lwP1TWSEh1698nnuhSzWrk3nhgkLueLy7xkwYDcT/3CK2+H5J0QSnC9DljeLiCTh7bt6m6ru++nrqjpJVbNUNSsmMjB/qHm53v0WFsTy3ezO9Dkqn4L8ODweQVWYNjWTPv3yA3Ls1rC3JJ52Sd57sNsllZBfcuDv8fSB2Uz/Pnirp/WpTo2m5Pi2IOItuQlEFFXvfz15bj7Fw0Kn1JObl0BubgJr16YDMHtOd448ci8dM4p5/tlPee2VD0lPL+XZp6aRmlrWyN5c5Gv1NAiSYEATnIhE401ub7rV8yE2rpr4+Kr9jwcfv5vNG9uQmla+f5uTTs5h88bAlB5bw9drMzln0DoAzhm0jq/XZO5/LTG2giE9cg5YFypKstoSv6oYgOiccqhWPMlOpcOjJM0roCiEElx+fjx79iTQtYv3e37wsTv54Yc0Lrn8F4y/ZhzjrxlHbm4CN906lvz84C2VCuE1bWCTiIgALwOrVfXxQB2nMampFfzhwbkAREYqX33ejUXzM/j9vQs5olchqrBrZwLP/GOwWyH65aELP+e4zB20TSjn49vfYNJXWbw2ezB/u2gG44asJqcgmXveP23/9qcctZF5P3SlvOrgC/TBJOPZjcSvLiayuJrMm1eQ94tO7BuVRsakLXS7ezUaKey+vsf+6mn8mmKq06Kp7hDbyJ6Dy3MvZHHXnd8SHeUhZ2cSjz851O2QmiQYkpcvRDUwkYrICGA28D0/TjM4UVU/qe89KXEddViP8QGJx027R2e4HULA5I8qb3yjENT7sUq3QwiIuWsmsa9kR7OaahMyumnvS25vfENg+dO3L1LVrOYcrzkCVoJT1W9o5r10xpggFSIluFZpRTXGhJEgub7mC0twxhj/WYIzxoSrUOmqZQnOGOM3q6IaY8JTkNzE6wtLcMYY/1mCM8aEo9qeDKEg4H1RjTHhRzzq09LofkReEZHdIrKizro0EZkhIuudn6nOehGRp0UkW0SWi8iQxvZvCc4Y45+W7Wz/KjD2J+vuBr5Q1d7AF85zgDOB3s4yAXi+sZ1bgjPG+K2lOtur6izgp2NPjgNecx6/BpxXZ/3r6jUXaCsinRravyU4Y4z/fC/BpYvIwjrLBB/2nuEMmAuwE++0B+AdMHdrne22OevqZY0Mxhi/+dHIkNuczvaqqiJNb9KwEpwxxn+BHfByV23V0/lZO4XadqBbne26OuvqZQnOGOMfZ1YtX5YmmgLUjps2HviwzvorndbUoUBhnarsIVkV1Rjjl5a8D05E3gZG471Wtw24D3gYeE9ErgU2Axc5m38CnAVkA6XA1Y3t3xKcMcZ/LTRQrqpeWs9LB01bqt7ReW/0Z/+W4IwxfguVngyW4Iwx/rHO9saYcGbjwRljwpYlOGNMeFJarJEh0IIuwUlNiHw1+CEyPGfWA6Dd53FuhxAQ668IrflWfVXxWGSL7McaGYwx4csSnDEmHIXSgJeW4Iwx/lHfBrMMBpbgjDH+C438ZgnOGOM/q6IaY8KTAlZFNcaErdDIb5bgjDH+syqqMSZsWSuqMSY82Wgixphw5b3RNzQynCU4Y4z/QqTLuCU4Y4zfrARnjAlPdg3OGBO+rC+qMSacWRXVGBOW1IYsN8aEMyvBGWPCVmjkN0twxhj/iSc06qiW4Iwx/lHsRl9jTHgS1G70DSavvP8ZZaVReDxCTY1w23Wj+dV1qxk6YieqUJAfyxMPDWZvXrzboTbqDxfOZPhRm8kvjueyJy4GoE18OQ9ePoPOqUXsyE/m3jdPp6gsFlBuP3cOJ/XdQnlVFA+8dwprd7R39wTq8YcLZjKi32byS+K59Kkfz+uhS2bQKbWInPxkJr59OkXlsZxx7DquHLkUESitiOaRD09m/c50l8/g0B4+4SvGdN5MXnk8Z0676IDXru27jImD55I1+UryK71/eyd22MEfBn9LVISH/Io4LvvyXDfCblyIJLiIQO1YROJEZL6ILBORlSJyf6CO5Yt7bhnOzVefwm3XjQbgg7d6cdNVp3Dz1acw/9sMLr16nZvh+Wzqor7c9vLZB6y7cvQSFmZ35cJHL2NhdleuHL0EgJP6bqFbeiEXPnopDwljONAAAAueSURBVE8exV3nz3YjZJ98vLgvt7564HmNH7WEBT905cLHL2PBD10ZP8p7Xjvy23DDi+O47OmLeHnmcdxz/iw3QvbJBxv7cPXXZx20vlNCMSM6bmN7SdL+dcnRFdx/3GwmzD6DMz+9iJvnnNaaofpH1bfFZQFLcEAFMEZVjwUGAWNFZGgAj+eXstLo/Y/j4mqC4bPwydKNndlXduCkxCOP3sTHi/oA8PGiPow6euP+9Z8u6gMIK7ZkkBxfQbvkktYO2SdLNnVmX+lPzuuoTXy8xDmvJX0Y1d97Xt9v6UhRuXfbFVsy6NCmuHWD9cOCPZ0pqDx4cux7B3/LI8uGHtAYeW6PbD7b1pOc0mQA8iqCtEZRew3Ol8VlAauiqqoCtX950c7iShpRFR54/DsAPv0wk2lTMgG4csIqxpyxlZKSaO65ZbgbobWItKQy8ooSAcgrSiAtqQyA9m1K2FX4Ywlhd2ES7duU7N822NV3XnWdm7Wa79Z1b+3QmuVnXTaxqzSRNQXtDljfM7mAqAgPb46ZQlJUFa+uG8h/N/VxKcqGWSsqICKRwCKgF/BPVZ0XyOPV567fjiAvN56UthU8+OS3bN2cxMpl6bw+qT+vT+rPL3+1jp9fsJE3X+nnRngtTEKmNOofOejb8bgjtnNu1homvHCeKxE1RVxkFb/pv4TxXx1cbY0UZUBqLlfMPIe4yGr+c9r/WJLXgU1FbV2ItCHBUf30RSCrqKhqjaoOAroCJ4jIgJ9uIyITRGShiCysrCkNSBx5ud6ifmFBLN/N6kTf/gUHvP7VjK6cNHpHQI7dGvYWx++verZLLiG/xHu+e/YlkpHyY/WtQ0oxe/aFRukNDnFexT9W2Xp1zOPe87/mzjfGUlh2cBUwWHVP2ke3xH18PPY/fP3zN+kYX8KUMyaTHlfKzrJEZu/sSllNNPmV8czf04mj2ua5HfLBFLsGV5eqFgAzgbGHeG2SqmapalZMZEKLHzs2rpr4+Kr9j4ccv5vNG5Lp3PXHf/yhI3aybXNSfbsIerNXZXL2cd5GkrOPW8eslZn715953DpAGdB9F8XlMSFTPQWYtTqTswc75zV4HbNWZwKQkVLEI5dP5773x7AlL9hKNw1bV9iOE/43nlEfXc6ojy5nZ1ki506/gNzyBD7fnklW+51Eioe4yCoGpe3mh32pbod8aIf7NTgRaQ9UqWqBiMQDpwGPBOp49UlNq+Dev84HIDJS+XpGFxbNy2Dig/Pp0r0Y9Qi7d8Xzz0ePbe3QmuSBSz9nyBE7aJtYzkcT32DSjCxe+2owf718Bucev5qc/GTufdPb+jZnTXdO6ruFD+56m/LKKB54f7S7wTfggYs/57ieznn9vzd48fMsXv96MH+9bAbnZq1mZ0EyE9/2ntd1YxaRklDO/zvX2ypc44lg/HO/cDP8ej057HNO7JBDamw535z7b55akcX7Gw59KeSHfanMyunGx2PfR1V4d0M/1hWmtXLEvgmV++BEAxSoiBwDvAZE4i0pvqeqf2noPSlxHfWkrlcEJB435Q7v5HYIAaORbkcQGHnHhMY/sL92PPYkFVu3SnP2kRLfSU/KvMqnbaeteXiRqmY153jNEchW1OXA4EDt3xjjElWoCYL6pw8Oi54MxpgW1kI1PxHZBBQBNUC1qmaJSBrwLpAJbAIuUtX8puy/VRoZjDFhpmVbUU9R1UF1qrJ3A1+oam/gC+d5k1iCM8b4RwGP+rY0zTi81+9xfjb5RkdLcMYYPymox7cF0mvvc3WWCQfvjM9EZFGd1zJUNcd5vBPIaGqkdg3OGOMfxZ9GhtxGWlFHqOp2EekAzBCRNQccSlVFpMlFQSvBGWP810LX4FR1u/NzN/Bf4ARgl4h0AnB+7m5qmJbgjDH+a4EEJyKJIpJc+xg4HVgBTAHGO5uNBz5saphWRTXG+KnF+plmAP8VEfDmordUdZqILADeE5Frgc3ARQ3so0GW4Iwx/lGgBYZLUtUNwEF9JFU1Dzi12QfAEpwxpilCpC+qJThjjJ+sq5YxJlwpqFqCM8aEq6b3UmhVluCMMf6za3DGmLCk2iKtqK3BEpwxxn9WgjPGhCdFa2rcDsInluCMMf6pHS4pBFiCM8b4z24TMcaEIwXUSnDGmLCkaiU4Y0z4CpVGhoDNi9oUIrIH7/AorSEdyG2lY7UmO6/Q05rn1kNV2zdnByIyDW/MvshV1bHNOV5zBFWCa00istDNCWkDxc4r9ITzubnNRvQ1xoQtS3DGmLB1OCe4SW4HECB2XqEnnM/NVYftNThjTPg7nEtwxpgwZwnOGBO2DrsEJyJjRWStiGSLyN1ux9NSROQVEdktIivcjqUliUg3EZkpIqtEZKWI3Op2TC1BROJEZL6ILHPO6363YwpHh9U1OBGJBNYBpwHbgAXApaq6ytXAWoCIjASKgddVdYDb8bQUZ2bzTqq62JkkeBFwXqh/ZuKdDDRRVYtFJBr4BrhVVee6HFpYOdxKcCcA2aq6QVUrgXeAcS7H1CJUdRaw1+04Wpqq5qjqYudxEbAa6OJuVM2nXsXO02hnOXxKG63kcEtwXYCtdZ5vIwz+WQ4XIpIJDAbmuRtJyxCRSBFZCuwGZqhqWJxXMDncEpwJUSKSBHwA3Kaq+9yOpyWoao2qDgK6AieISNhcWggWh1uC2w50q/O8q7POBDHnGtUHwJuqOtnteFqaqhYAMwHXOqWHq8MtwS0AeotITxGJAS4Bprgck2mAczH+ZWC1qj7udjwtRUTai0hb53E83oavNe5GFX4OqwSnqtXATcB0vBer31PVle5G1TJE5G3gO6CviGwTkWvdjqmFDAeuAMaIyFJnOcvtoFpAJ2CmiCzH+8U7Q1WnuhxT2DmsbhMxxhxeDqsSnDHm8GIJzhgTtizBGWPCliU4Y0zYsgRnjAlbluBCiIjUOLdJrBCR90UkoRn7elVELnQevyQi/RvYdrSInNSEY2wSkYNmX6pv/U+2KW7o9UNs/2cR+b2/MZrwZgkutJSp6iBntJBK4Ia6L4pIk+a5VdXrGhmdYzTgd4Izxm2W4ELXbKCXU7qaLSJTgFVOB+5HRWSBiCwXkevB2yNARJ51xsL7HOhQuyMR+UpEspzHY0VksTNO2RdOB/cbgN85pceTnbvwP3COsUBEhjvvbScinznjm70ESGMnISL/E5FFznsm/OS1J5z1X4hIe2fdkSIyzXnPbBHp1xK/TBOebGb7EOSU1M4EpjmrhgADVHWjkyQKVfV4EYkF5ojIZ3hH4egL9AcygFXAKz/Zb3vgRWCks680Vd0rIv8CilX1H852bwFPqOo3ItIdb8+Qo4D7gG9U9S8icjbgS2+Ka5xjxAMLROQDVc0DEoGFqvo7EfmTs++b8E7QcoOqrheRE4HngDFN+DWaw4AluNAS7wyvA94S3Mt4q47zVXWjs/504Jja62tACtAbGAm8rao1wA4R+fIQ+x8KzKrdl6rWN77cz4D+3m6iALRxRvsYCVzgvPdjEcn34ZxuEZHzncfdnFjzAA/wrrP+38Bk5xgnAe/XOXasD8cwhylLcKGlzBleZz/nH72k7irgZlWd/pPtWrL/ZgQwVFXLDxGLz0RkNN5kOUxVS0XkKyCuns3VOW7BT38HxtTHrsGFn+nAb5whhhCRPiKSCMwCLnau0XUCTjnEe+cCI0Wkp/PeNGd9EZBcZ7vPgJtrn4hIbcKZBVzmrDsTSG0k1hQg30lu/fCWIGtFALWl0MvwVn33ARtF5JfOMUREjm3kGOYwZgku/LyE9/raYvFOQPMC3pL6f4H1zmuv4x155ACqugeYgLc6uIwfq4gfAefXNjIAtwBZTiPGKn5szb0fb4JcibequqWRWKcBUSKyGngYb4KtVYJ3EMgVeK+x/cVZfzlwrRPfSsJkyHkTGDaaiDEmbFkJzhgTtizBGWPCliU4Y0zYsgRnjAlbluCMMWHLEpwxJmxZgjPGhK3/D5Y38PSHzQbJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}